{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ArcFace\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arcface_weights.h5  will be downloaded to  C:\\Users\\Arianpc/.deepface/weights/arcface_weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1LVB3CdVejpmGHM28BpqqkbZP5hDEcdZY\n",
      "To: C:\\Users\\Arianpc\\.deepface\\weights\\arcface_weights.h5\n",
      "100%|██████████| 137M/137M [02:30<00:00, 913kB/s]  \n"
     ]
    }
   ],
   "source": [
    "model = ArcFace.loadModel()\n",
    "face_detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #mtcnn expects RGB but OpenCV read BGR\n",
    "    detections = face_detector.detect_faces(img_rgb)\n",
    "    detection = detections[0]\n",
    "    x, y, w, h = detection[\"box\"]\n",
    "    detected_face = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "    return detected_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_face(img, target_size=(112,112)):\n",
    "    img = cv2.imread(img)\n",
    "    img = detect_face(img)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img_pixels = image.img_to_array(img)\n",
    "    img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "    img_pixels /= 255 #normalize input in [0, 1]\n",
    "    return img_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding(path):\n",
    "    img = preprocess_face(path)\n",
    "    return model.predict(img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "\n",
    "database[\"maryam\"] = img_to_encoding(\"maryam1.jpg\")\n",
    "database[\"mahmoud\"] = img_to_encoding(\"mahmoud1 (1).jpg\")\n",
    "database[\"masoud\"] = img_to_encoding(\"masoud_fekri1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EuclideanDistance(source_representation, test_representation):\n",
    "    euclidean_distance = source_representation - test_representation\n",
    "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "    euclidean_distance = np.sqrt(euclidean_distance)\n",
    "    return euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_threshhold = 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(image_path, identity, database):\n",
    "    # Step 1: Compute the encoding for the image. Use img_to_encoding()\n",
    "    encoding = img_to_encoding(image_path) \n",
    "    \n",
    "    # Step 2: Compute distance with identity's image\n",
    "    dist = EuclideanDistance(encoding, database[identity])\n",
    "    \n",
    "    # Step 3: Open the door if dist < verification_threshhold, else don't open\n",
    "    if dist < verification_threshhold:\n",
    "        print(\"It's \" + str(identity) + \", welcome!\")\n",
    "    else:\n",
    "        print(\"It's not \" + str(identity) + \", please go away\")\n",
    "             \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's mahmoud, welcome!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.4052253"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "verify(\"mahmoud2 .jpg\", \"mahmoud\", database)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
